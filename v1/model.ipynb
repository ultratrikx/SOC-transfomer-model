{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 999 scenes\n",
      "Using threshold=332.0718688964844 for F1 and Kappa computation.\n",
      "Epoch 1/10: Train Loss=10160107.3625, Val Loss=9360532.5969, Val MSE=9360532.0000, F1=0.0000, Kappa=0.0000\n",
      "Epoch 2/10: Train Loss=10175212.2406, Val Loss=9358676.7756, Val MSE=9358677.0000, F1=0.0000, Kappa=0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 155\u001b[0m\n\u001b[0;32m    153\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    154\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 155\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlandsat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoil_val\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlandsat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlandsat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (B,6,80,80)\u001b[39;49;00m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43msoil_val\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msoil_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rohan\\carbon-seq-model\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Rohan\\carbon-seq-model\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Rohan\\carbon-seq-model\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Rohan\\carbon-seq-model\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[17], line 52\u001b[0m, in \u001b[0;36mSoilCarbonDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m band_files:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBand \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mband_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found for scene \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscene\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrasterio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mband_files\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mband_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# shape: (80,80)\u001b[39;49;00m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlandsat_bands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mband_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mrasterio\\\\_base.pyx:445\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__enter__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\contextlib.py:526\u001b[0m, in \u001b[0;36m_BaseExitStack.enter_context\u001b[1;34m(self, cm)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object does \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot support the context manager protocol\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 526\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_enter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_push_cm_exit(cm, _exit)\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Rohan\\carbon-seq-model\\venv\\Lib\\site-packages\\rasterio\\env.py:299\u001b[0m, in \u001b[0;36mEnv.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m             local\u001b[38;5;241m.\u001b[39m_discovered_options[key] \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m--> 299\u001b[0m     \u001b[43mdefenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_options \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Rohan\\carbon-seq-model\\venv\\Lib\\site-packages\\rasterio\\env.py:338\u001b[0m, in \u001b[0;36mdefenv\u001b[1;34m(**options)\u001b[0m\n\u001b[0;32m    335\u001b[0m     local\u001b[38;5;241m.\u001b[39m_env\u001b[38;5;241m.\u001b[39mupdate_config_options(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    336\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew GDAL environment \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m created\u001b[39m\u001b[38;5;124m\"\u001b[39m, local\u001b[38;5;241m.\u001b[39m_env)\n\u001b[1;32m--> 338\u001b[0m \u001b[43mlocal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mrasterio\\\\_env.pyx:402\u001b[0m, in \u001b[0;36mrasterio._env.GDALEnv.start\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\logging\\__init__.py:1517\u001b[0m, in \u001b[0;36mLogger.debug\u001b[1;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m=\u001b[39m _checkLevel(level)\n\u001b[0;32m   1515\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanager\u001b[38;5;241m.\u001b[39m_clear_cache()\n\u001b[1;32m-> 1517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdebug\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;124;03m    Log 'msg % args' with severity 'DEBUG'.\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;124;03m    logger.debug(\"Houston, we have a %s\", \"thorny problem\", exc_info=True)\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misEnabledFor(DEBUG):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score\n",
    "import timm\n",
    "\n",
    "########################################\n",
    "# Configuration\n",
    "########################################\n",
    "# Use relative or absolute paths to your data directories\n",
    "landsat_dir = 'landsat_model'  # contains sceneName_B1.tif ... sceneName_B6.tif\n",
    "soil_dir = 'soilgrid_model'    # contains sceneName_B1.tif for soil\n",
    "\n",
    "# Check if directories exist\n",
    "if not os.path.exists(landsat_dir):\n",
    "    raise FileNotFoundError(f\"Landsat directory not found: {landsat_dir}\")\n",
    "if not os.path.exists(soil_dir):\n",
    "    raise FileNotFoundError(f\"Soil directory not found: {soil_dir}\")\n",
    "\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 10\n",
    "threshold = None  # Will set this after we have training data stats\n",
    "\n",
    "########################################\n",
    "# Dataset\n",
    "########################################\n",
    "class SoilCarbonDataset(Dataset):\n",
    "    def __init__(self, landsat_dir, soil_dir, scene_list):\n",
    "        self.landsat_dir = landsat_dir\n",
    "        self.soil_dir = soil_dir\n",
    "        self.scenes = scene_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.scenes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.scenes[idx]\n",
    "    \n",
    "        # Read the 6 Landsat bands\n",
    "        landsat_bands = []\n",
    "        for band_num in [1, 2, 3, 4, 5, 7]:  # bands 1-5,7\n",
    "            band_pattern = os.path.join(self.landsat_dir, f\"{scene}_*_b{band_num}.tif\")\n",
    "            band_files = glob.glob(band_pattern)\n",
    "            if not band_files:\n",
    "                raise FileNotFoundError(f\"Band {band_num} not found for scene {scene}\")\n",
    "            with rasterio.open(band_files[0]) as src:\n",
    "                band_data = src.read(1)  # shape: (80,80)\n",
    "                landsat_bands.append(band_data)\n",
    "        \n",
    "        # Stack Landsat bands\n",
    "        landsat_img = np.stack(landsat_bands, axis=0)  # shape: (6,80,80)\n",
    "        \n",
    "        # Read soil data\n",
    "        soil_pattern = os.path.join(self.soil_dir, f\"{scene}_*_s1.tif\")\n",
    "        soil_files = glob.glob(soil_pattern)\n",
    "        if not soil_files:\n",
    "            raise FileNotFoundError(f\"Soil data not found for scene {scene}\")\n",
    "        with rasterio.open(soil_files[0]) as src:\n",
    "            soil_data = src.read(1).astype(np.float32)  # ensure float32\n",
    "        soil_val = np.mean(soil_data)\n",
    "\n",
    "        # Convert to tensors\n",
    "        landsat_img = torch.from_numpy(landsat_img).float()  # (6,80,80)\n",
    "        soil_val = torch.tensor(soil_val).float()\n",
    "        \n",
    "        return landsat_img, soil_val\n",
    "    \n",
    "########################################\n",
    "# Prepare Data\n",
    "########################################\n",
    "# Find all scenes by listing Landsat directory and extracting the base scene numbers\n",
    "landsat_files = glob.glob(os.path.join(landsat_dir, \"*_b1.tif\"))\n",
    "if not landsat_files:\n",
    "    raise FileNotFoundError(f\"No Landsat files found in {landsat_dir}\")\n",
    "scenes = [os.path.basename(f).split('_')[0] for f in landsat_files]\n",
    "print(f\"Found {len(scenes)} scenes\")\n",
    "\n",
    "dataset = SoilCarbonDataset(landsat_dir, soil_dir, scenes)\n",
    "\n",
    "# Split into train/val\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Compute threshold for binary classification metrics (F1, Kappa)\n",
    "# We'll use median soil value from the training set\n",
    "all_train_soil_vals = []\n",
    "for i in range(len(train_dataset)):\n",
    "    # get train dataset indices\n",
    "    landsat_img, soil_val = train_dataset[i]\n",
    "    all_train_soil_vals.append(soil_val.item())\n",
    "threshold = np.median(all_train_soil_vals)\n",
    "print(f\"Using threshold={threshold} for F1 and Kappa computation.\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "########################################\n",
    "# Model\n",
    "########################################\n",
    "# Create ViT model from timm and adapt first layer for 6 channels and last layer for regression\n",
    "model = timm.create_model('vit_small_patch16_224', pretrained=False, num_classes=1)\n",
    "\n",
    "# Adapt input conv layer to 6 channels (instead of 3)\n",
    "original_conv = model.patch_embed.proj\n",
    "model.patch_embed.proj = nn.Conv2d(6, original_conv.out_channels, \n",
    "                                   kernel_size=original_conv.kernel_size,\n",
    "                                   stride=original_conv.stride,\n",
    "                                   padding=original_conv.padding)\n",
    "\n",
    "# The model expects 224x224 input. We have 80x80.\n",
    "# For simplicity, resize input in the forward pass (quick hack).\n",
    "# A better solution: modify model.patch_embed.patch_size or use another model more suited to 80x80.\n",
    "resize = nn.Upsample(size=(224,224), mode='bilinear', align_corners=False)\n",
    "\n",
    "# Check if CUDA is available and use it, otherwise use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "########################################\n",
    "# Loss and Optimizer\n",
    "########################################\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "########################################\n",
    "# Utility functions for metrics\n",
    "########################################\n",
    "def compute_metrics(y_true, y_pred, threshold):\n",
    "    # y_true, y_pred are arrays of floats\n",
    "    # Convert to binary\n",
    "    y_true_bin = (y_true >= threshold).astype(int)\n",
    "    y_pred_bin = (y_pred >= threshold).astype(int)\n",
    "\n",
    "    mse = np.mean((y_true - y_pred)**2)\n",
    "    f1 = f1_score(y_true_bin, y_pred_bin)\n",
    "    kappa = cohen_kappa_score(y_true_bin, y_pred_bin)\n",
    "\n",
    "    return mse, f1, kappa\n",
    "\n",
    "########################################\n",
    "# Training Loop\n",
    "########################################\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for landsat, soil_val in train_loader:\n",
    "        landsat = landsat.to(device)  # (B,6,80,80)\n",
    "        soil_val = soil_val.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        landsat_resized = resize(landsat)  # (B,6,224,224)\n",
    "        preds = model(landsat_resized)  # (B,1)\n",
    "        loss = criterion(preds.squeeze(), soil_val)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    all_val_true = []\n",
    "    all_val_pred = []\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for landsat, soil_val in val_loader:\n",
    "            landsat = landsat.to(device)\n",
    "            soil_val = soil_val.to(device)\n",
    "            landsat_resized = resize(landsat)\n",
    "            preds = model(landsat_resized)\n",
    "            val_loss += criterion(preds.squeeze(), soil_val).item()\n",
    "            \n",
    "            all_val_true.append(soil_val.cpu().numpy())\n",
    "            all_val_pred.append(preds.squeeze().cpu().numpy())\n",
    "\n",
    "    all_val_true = np.concatenate(all_val_true)\n",
    "    all_val_pred = np.concatenate(all_val_pred)\n",
    "    mse_val, f1_val, kappa_val = compute_metrics(all_val_true, all_val_pred, threshold)\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}, Val MSE={mse_val:.4f}, F1={f1_val:.4f}, Kappa={kappa_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
